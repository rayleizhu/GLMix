
partition: "mediaa" # Partition where to submit
ngpus: 8 # Number of gpus to request on each node
nodes: 1 # Number of nodes to request
cpus_per_task: 5 # Number of cpus per task/gpu
timeout: 240 # Duration of the job, in hours
job_name: "${model}" # job_name to display with `squeue`
job_dir: ~ # Job directory; leave empty for default (hydra.run.dir)
# exclude_node: "SH-IDC1-10-198-4-35,SH-IDC1-10-198-4-41,SH-IDC1-10-198-4-54,SH-IDC1-10-198-4-56,SH-IDC1-10-198-4-75,SH-IDC1-10-198-4-76,SH-IDC1-10-198-4-78,SH-IDC1-10-198-4-120,SH-IDC1-10-198-4-153" # The node(s) to be excluded for slurm assignment
# exclude_node: ~ # The node(s) to be excluded for slurm assignment
exclude_node: "SH-IDC1-10-198-4-[35,41,43,44,54,56,70,75,76,77,78,81,83,112,113,115,120,121,122,153,184,185,246]"
comment: ~ # Comment to pass to scheduler, e.g. priority message
quotatype: "spot"
phx_priority: "leisure"

ddp_comm_mode: "tcp" # ddp communication mode, "file" or "tcp"
# position to put DDP communication file (as an alternative of port based sychronisation)
# this path must be accessible by all machines, for "file" mode only
share_root: "/mnt/lustre/zhulei1/checkpoint/${project}"
# master_port: 29500 # for "tcp" mode only
master_port: ~ # for "tcp" mode only, leave empty to find available one automatically


# Tips:
# show job info:
# - scontrol show job [JOBID]
# update exclude list for a RUNNING job when meet broken node:
# 1. scontrol requeuehold [JOBID]
# 2. scontrol update JobId=[JOBID] ExcNodeList=SH-IDC1-10-198-4-[35,41,43,44,54,56,75,76,77,78,81,83,113,115,120,122,153,184,185] 
# 3. scontrol relesase [JOBID]
# occupy nodes temporally
# srun -p mediaa --gres=gpu:8 --ntasks-per-node=8 --ntasks=[NODES*8] python -i
